"""
FEW-SHOT LEARNING v·ªõi CLIP
================================
Ph√¢n lo·∫°i ·∫£nh s·ª≠ d·ª•ng K support examples cho m·ªói class (K=1,5,10)
Prototype-based classification: T√≠nh mean c·ªßa support features l√†m prototype

"""

import os
import random
import torch
import clip
from PIL import Image
import matplotlib
matplotlib.use('Agg')  # Backend kh√¥ng c·∫ßn GUI
import matplotlib.pyplot as plt
import numpy as np


# ================================================================================
# C·∫§U H√åNH H·ªÜ TH·ªêNG
# ================================================================================

# 10 classes t·ª´ CIFAR-10
CLASS_NAMES = [
    "airplane", "automobile", "bird", "cat", "deer",
    "dog", "frog", "horse", "ship", "truck"
]

# C√°c t√πy ch·ªçn K-shot
K_SHOT_OPTIONS = {
    '1': 1,   # 1-shot: 1 example/class
    '2': 5,   # 5-shot: 5 examples/class
    '3': 10   # 10-shot: 10 examples/class
}


# ================================================================================
# 1. LOAD CLIP MODEL
# ================================================================================

def load_clip_model():
    """Load CLIP ViT-B/32 model"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"\n{'='*80}")
    print(f"üîß ƒêANG KH·ªûI T·∫†O H·ªÜ TH·ªêNG FEW-SHOT LEARNING")
    print(f"{'='*80}")
    print(f"üìå Device: {device.upper()}")
    
    model, preprocess = clip.load("ViT-B/32", device=device)
    model.eval()
    
    print(f"‚úÖ ƒê√£ load CLIP ViT-B/32 successfully!")
    print(f"üìä Embedding dimension: 512")
    print(f"üéØ Classes: {len(CLASS_NAMES)} (CIFAR-10)")
    
    return model, preprocess, device


# ================================================================================
# 2. BUILD SUPPORT SET
# ================================================================================

def build_support_set(images_dir, k_shot):
    """
    T·∫°o support set v·ªõi K examples cho m·ªói class
    
    Args:
        images_dir: Th∆∞ m·ª•c ch·ª©a ·∫£nh (c√≥ 10 folders con)
        k_shot: S·ªë l∆∞·ª£ng examples/class (1, 5, ho·∫∑c 10)
    
    Returns:
        support_set: Dict {class_name: [list of K image paths]}
    """
    support_set = {}
    
    print(f"\n{'='*80}")
    print(f"üìÅ ƒêANG X√ÇY D·ª∞NG SUPPORT SET ({k_shot}-SHOT)")
    print(f"{'='*80}")
    
    for class_name in CLASS_NAMES:
        class_dir = os.path.join(images_dir, class_name)
        
        if not os.path.exists(class_dir):
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y folder: {class_name}")
            continue
        
        # L·∫•y t·∫•t c·∫£ ·∫£nh trong folder
        all_images = [f for f in os.listdir(class_dir) 
                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if len(all_images) < k_shot:
            print(f"‚ö†Ô∏è  {class_name}: Ch·ªâ c√≥ {len(all_images)} ·∫£nh (c·∫ßn {k_shot})")
            selected = all_images
        else:
            # Random ch·ªçn K ·∫£nh
            selected = random.sample(all_images, k_shot)
        
        # L∆∞u ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß
        support_set[class_name] = [
            os.path.join(class_dir, img) for img in selected
        ]
        
        print(f"‚úÖ {class_name:12s}: {len(support_set[class_name])} examples")
    
    total_examples = sum(len(imgs) for imgs in support_set.values())
    print(f"\nüìä T·ªïng s·ªë examples: {total_examples} ·∫£nh")
    print(f"üìà Expected: {len(CLASS_NAMES)} classes √ó {k_shot} = {len(CLASS_NAMES) * k_shot} ·∫£nh")
    
    return support_set


# ================================================================================
# 3. ENCODE SUPPORT SET
# ================================================================================

def encode_support_set(model, preprocess, support_set, device):
    """
    Encode t·∫•t c·∫£ support images v√† t√≠nh prototypes
    
    Args:
        model: CLIP model
        preprocess: CLIP preprocessing function
        support_set: Dict {class_name: [image_paths]}
        device: 'cuda' or 'cpu'
    
    Returns:
        prototypes: Tensor [num_classes, 512] - Mean features cho m·ªói class
        class_order: List of class names (ƒë·ªÉ map index -> class)
    """
    print(f"\n{'='*80}")
    print(f"üîÑ ƒêANG ENCODE SUPPORT SET & T√çNH PROTOTYPES")
    print(f"{'='*80}")
    
    prototypes = []
    class_order = []
    
    with torch.no_grad():
        for class_name in CLASS_NAMES:
            if class_name not in support_set:
                continue
            
            image_paths = support_set[class_name]
            features_list = []
            
            # Encode t·ª´ng ·∫£nh trong support set
            for img_path in image_paths:
                image = preprocess(Image.open(img_path)).unsqueeze(0).to(device)
                features = model.encode_image(image)
                features = features / features.norm(dim=-1, keepdim=True)
                features_list.append(features)
            
            # T√≠nh prototype = mean c·ªßa all support features
            class_features = torch.cat(features_list, dim=0)
            prototype = class_features.mean(dim=0, keepdim=True)
            prototype = prototype / prototype.norm(dim=-1, keepdim=True)
            
            prototypes.append(prototype)
            class_order.append(class_name)
            
            print(f"‚úÖ {class_name:12s}: {len(features_list)} examples ‚Üí 1 prototype [512-dim]")
    
    prototypes = torch.cat(prototypes, dim=0)  # [num_classes, 512]
    
    print(f"\nüìä Prototypes shape: {list(prototypes.shape)}")
    print(f"‚úÖ ƒê√£ t√≠nh {len(class_order)} prototypes successfully!")
    
    return prototypes, class_order


# ================================================================================
# 4. FEW-SHOT CLASSIFICATION
# ================================================================================

def few_shot_classify(model, preprocess, query_image_path, prototypes, class_order, device):
    """
    Ph√¢n lo·∫°i 1 query image b·∫±ng Few-shot learning
    
    Args:
        model: CLIP model
        preprocess: CLIP preprocessing function
        query_image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn query image
        prototypes: Tensor [num_classes, 512]
        class_order: List of class names
        device: 'cuda' or 'cpu'
    
    Returns:
        predicted_class: T√™n class ƒë∆∞·ª£c d·ª± ƒëo√°n
        confidence: ƒê·ªô tin c·∫≠y (%)
        probabilities: Dict {class_name: probability}
    """
    # Load v√† encode query image
    query_image = preprocess(Image.open(query_image_path)).unsqueeze(0).to(device)
    
    with torch.no_grad():
        query_features = model.encode_image(query_image)
        query_features = query_features / query_features.norm(dim=-1, keepdim=True)
        
        # T√≠nh cosine similarity v·ªõi c√°c prototypes
        similarities = (query_features @ prototypes.T).squeeze(0)  # [num_classes]
        
        # Softmax ƒë·ªÉ ra probabilities
        probabilities_tensor = torch.softmax(similarities * 100, dim=0)
        
        # Predicted class
        pred_idx = similarities.argmax().item()
        predicted_class = class_order[pred_idx]
        confidence = probabilities_tensor[pred_idx].item() * 100
        
        # Convert to dict
        probabilities = {
            class_order[i]: probabilities_tensor[i].item() * 100 
            for i in range(len(class_order))
        }
    
    return predicted_class, confidence, probabilities


# ================================================================================
# 5. VISUALIZATION
# ================================================================================

def visualize_result(query_image_path, predicted_class, probabilities, true_class=None):
    """
    T·∫°o visualization cho k·∫øt qu·∫£ ph√¢n lo·∫°i
    
    Args:
        query_image_path: ƒê∆∞·ªùng d·∫´n query image
        predicted_class: Class ƒë∆∞·ª£c d·ª± ƒëo√°n
        probabilities: Dict {class_name: probability}
        true_class: True label (n·∫øu c√≥)
    """
    # T·∫°o figure v·ªõi 2 subplots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    # Subplot 1: Hi·ªÉn th·ªã ·∫£nh
    img = Image.open(query_image_path)
    ax1.imshow(img)
    ax1.axis('off')
    
    if true_class:
        status = "‚úÖ CORRECT" if predicted_class == true_class else "‚ùå WRONG"
        title = f"True: {true_class} | Pred: {predicted_class}\n{status}"
    else:
        title = f"Predicted: {predicted_class}"
    
    ax1.set_title(title, fontsize=12, fontweight='bold')
    
    # Subplot 2: Bar chart x√°c su·∫•t
    classes = list(probabilities.keys())
    probs = list(probabilities.values())
    
    colors = ['#2ecc71' if c == predicted_class else '#3498db' for c in classes]
    
    bars = ax2.barh(classes, probs, color=colors)
    ax2.set_xlabel('Probability (%)', fontsize=10)
    ax2.set_title('Class Probabilities', fontsize=12, fontweight='bold')
    ax2.set_xlim(0, 100)
    
    # Th√™m gi√° tr·ªã v√†o bars
    for bar, prob in zip(bars, probs):
        width = bar.get_width()
        ax2.text(width + 1, bar.get_y() + bar.get_height()/2, 
                f'{prob:.2f}%', ha='left', va='center', fontsize=9)
    
    plt.tight_layout()
    
    # L∆∞u file v√†o folder results/
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    results_dir = os.path.join(project_root, "results")
    os.makedirs(results_dir, exist_ok=True)
    
    output_file = os.path.join(results_dir, 'few_shot_result.png')
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    plt.close()
    
    return output_file


# ================================================================================
# 6. RANDOM TEST
# ================================================================================

def random_test(images_dir, model, preprocess, prototypes, class_order, device):
    """Random ch·ªçn 1 ·∫£nh ƒë·ªÉ test"""
    # Random ch·ªçn class
    true_class = random.choice(CLASS_NAMES)
    class_dir = os.path.join(images_dir, true_class)
    
    if not os.path.exists(class_dir):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y folder: {true_class}")
        return None
    
    # L·∫•y list ·∫£nh
    images = [f for f in os.listdir(class_dir) 
             if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    if not images:
        print(f"‚ùå Kh√¥ng c√≥ ·∫£nh trong folder: {true_class}")
        return None
    
    # Random ch·ªçn 1 ·∫£nh
    selected_image = random.choice(images)
    query_path = os.path.join(class_dir, selected_image)
    
    print(f"\n{'='*80}")
    print(f"üé≤ RANDOM TEST")
    print(f"{'='*80}")
    print(f"üìÅ True class: {true_class}")
    print(f"üñºÔ∏è  Image: {selected_image}")
    print(f"üìç Path: {query_path}")
    
    # Classify
    print(f"\nüîÑ ƒêang ph√¢n lo·∫°i...")
    predicted_class, confidence, probabilities = few_shot_classify(
        model, preprocess, query_path, prototypes, class_order, device
    )
    
    # K·∫øt qu·∫£
    print(f"\n{'='*80}")
    print(f"üìä K·∫æT QU·∫¢ PH√ÇN LO·∫†I")
    print(f"{'='*80}")
    print(f"üéØ Predicted: {predicted_class}")
    print(f"üìà Confidence: {confidence:.2f}%")
    print(f"‚úÖ True class: {true_class}")
    
    if predicted_class == true_class:
        print(f"üéâ Status: CORRECT ‚úÖ")
        result = True
    else:
        print(f"‚ùå Status: WRONG")
        result = False
    
    # Top-5
    print(f"\nüìä Top-5 Predictions:")
    sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)
    for i, (cls, prob) in enumerate(sorted_probs[:5], 1):
        marker = "‚úì" if cls == true_class else " "
        print(f"  {i}. {cls:12s} {prob:6.2f}% {marker}")
    
    # Visualization
    output_file = visualize_result(query_path, predicted_class, probabilities, true_class)
    print(f"\nüíæ ƒê√£ l∆∞u visualization: {output_file}")
    
    return result


# ================================================================================
# 7. STATISTICS TRACKING
# ================================================================================

class Statistics:
    def __init__(self):
        self.total_tests = 0
        self.correct = 0
        self.wrong = 0
    
    def update(self, is_correct):
        self.total_tests += 1
        if is_correct:
            self.correct += 1
        else:
            self.wrong += 1
    
    def get_accuracy(self):
        if self.total_tests == 0:
            return 0.0
        return (self.correct / self.total_tests) * 100
    
    def display(self):
        print(f"\n{'='*80}")
        print(f"üìä STATISTICS (Session)")
        print(f"{'='*80}")
        print(f"üî¢ Total tests: {self.total_tests}")
        print(f"‚úÖ Correct: {self.correct}")
        print(f"‚ùå Wrong: {self.wrong}")
        print(f"üìà Accuracy: {self.get_accuracy():.2f}%")
        print(f"{'='*80}")


# ================================================================================
# 8. MENU H·ªÜ TH·ªêNG
# ================================================================================

def display_menu():
    """Hi·ªÉn th·ªã menu ch√≠nh"""
    print(f"\n{'='*80}")
    print(f"üéØ FEW-SHOT LEARNING - MENU CH√çNH")
    print(f"{'='*80}")
    print(f"1. Random test (1 ·∫£nh)")
    print(f"2. Continuous test (nhi·ªÅu ·∫£nh li√™n ti·∫øp)")
    print(f"3. Xem statistics")
    print(f"4. ƒê·ªïi K-shot (hi·ªán t·∫°i: {current_k_shot})")
    print(f"5. Rebuild support set")
    print(f"0. Tho√°t")
    print(f"{'='*80}")


def select_k_shot():
    """Ch·ªçn K-shot (1, 5, ho·∫∑c 10)"""
    print(f"\n{'='*80}")
    print(f"üéØ CH·ªåN K-SHOT")
    print(f"{'='*80}")
    print(f"1. 1-shot (1 example/class)")
    print(f"2. 5-shot (5 examples/class)")
    print(f"3. 10-shot (10 examples/class)")
    print(f"{'='*80}")
    
    while True:
        choice = input("üëâ Nh·∫≠p l·ª±a ch·ªçn (1-3): ").strip()
        if choice in K_SHOT_OPTIONS:
            return K_SHOT_OPTIONS[choice]
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p 1, 2, ho·∫∑c 3.")


# ================================================================================
# 9. MAIN FUNCTION
# ================================================================================

def main():
    global current_k_shot
    
    # Setup - L·∫•y ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c g·ªëc c·ªßa project (parent c·ªßa src/)
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    images_dir = os.path.join(project_root, "images")
    
    # Load CLIP
    model, preprocess, device = load_clip_model()
    
    # Ch·ªçn K-shot
    current_k_shot = select_k_shot()
    
    # Build support set
    support_set = build_support_set(images_dir, current_k_shot)
    prototypes, class_order = encode_support_set(model, preprocess, support_set, device)
    
    # Statistics
    stats = Statistics()
    
    # Main loop
    while True:
        display_menu()
        choice = input("üëâ Nh·∫≠p l·ª±a ch·ªçn: ").strip()
        
        if choice == '1':
            # Random test 1 ·∫£nh
            result = random_test(images_dir, model, preprocess, prototypes, class_order, device)
            if result is not None:
                stats.update(result)
        
        elif choice == '2':
            # Continuous test
            print("\nüîÑ CONTINUOUS TEST MODE")
            print("Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng\n")
            
            try:
                count = 0
                while True:
                    count += 1
                    print(f"\n{'#'*80}")
                    print(f"TEST #{count}")
                    print(f"{'#'*80}")
                    
                    result = random_test(images_dir, model, preprocess, prototypes, class_order, device)
                    if result is not None:
                        stats.update(result)
                    
                    input("\n‚è∏Ô∏è  Nh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            
            except KeyboardInterrupt:
                print("\n\n‚èπÔ∏è  ƒê√£ d·ª´ng continuous test.")
        
        elif choice == '3':
            # Xem statistics
            stats.display()
        
        elif choice == '4':
            # ƒê·ªïi K-shot
            new_k_shot = select_k_shot()
            if new_k_shot != current_k_shot:
                current_k_shot = new_k_shot
                print(f"\nüîÑ ƒêang rebuild support set v·ªõi {current_k_shot}-shot...")
                support_set = build_support_set(images_dir, current_k_shot)
                prototypes, class_order = encode_support_set(model, preprocess, support_set, device)
                print(f"‚úÖ ƒê√£ rebuild support set!")
        
        elif choice == '5':
            # Rebuild support set (v·ªõi same K)
            print(f"\nüîÑ ƒêang rebuild support set v·ªõi {current_k_shot}-shot...")
            support_set = build_support_set(images_dir, current_k_shot)
            prototypes, class_order = encode_support_set(model, preprocess, support_set, device)
            print(f"‚úÖ ƒê√£ rebuild support set!")
        
        elif choice == '0':
            # Tho√°t
            print(f"\n{'='*80}")
            print(f"üëã C·∫¢M ∆†N B·∫†N ƒê√É S·ª¨ D·ª§NG FEW-SHOT LEARNING!")
            stats.display()
            print(f"{'='*80}\n")
            break
        
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i.")


if __name__ == "__main__":
    current_k_shot = 5  # Default
    main()